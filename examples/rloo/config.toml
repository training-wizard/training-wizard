# Train the ranker model on the blind eval ranking data
spec_class = "training_wizard.recipes.rloo.RLOOTrainingSpec"
validation = 5

[reward_spec]
spec_class = "examples.rloo.reward_spec.Seq2SeqClassifierRewardSpec"
source_capture_regex = "<\\|im_start\\|>user\n(.*?)<\\|im_end\\|>"
source_capture_regex_group = 1
target_capture_regex = "(.*?)(?:<\\|im_end\\|>|$)"
target_capture_regex_group = 1
input_template = "{source}\n\n{target}\n\nScore:"

[reward_spec.transformer_spec]
pretrained_name = "Qwen/Qwen2.5-0.5B-Instruct"
device_map = "cuda"

[reward_spec.transformer_spec.from_pretrained_kwargs]
torch_dtype = "bfloat16"
num_labels = 1

[transformer_spec]
pretrained_name = "llamafactory/tiny-random-Llama-3"

[transformer_spec.tokenizer_call_kwargs]
max_length = 1024
truncation = true

[dataset_spec]
spec_class = "training_wizard.specs.dataset.TemplateInstructDatasourceSpec"
output_column = "prompt"

[dataset_spec.parent]
spec_class = "training_wizard.specs.dataset.SimpleDataSourceSpec"
data_files = "examples/data/diverse_sample_100.jsonl"

[[dataset_spec.messages_template]]
role = "user"
content = """You are multilingual paraphraser. Only answer with a paraphrase of the input:
{input}"""

[training_args_spec]
run_name = "Qwen Mini RLOO Test"
output_dir = "examples/rloo/output"
warmup_steps = 100
logging_steps = 10
num_train_epochs = 1
per_device_train_batch_size = 2
per_device_eval_batch_size = 2
bf16 = true
optim = "adamw_bnb_8bit"

# RLHF
num_ppo_epochs = 4
whiten_rewards = false
kl_coef = 0.05
cliprange = 0.2
rloo_k = 2
learning_rate = 1e-6

# Generation
temperature = 0.5

# Training
gradient_checkpointing = true
gradient_accumulation_steps = 1
save_only_model = true
